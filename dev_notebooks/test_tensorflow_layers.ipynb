{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "from nems import Model\n",
    "from nems.tf.model import build_model\n",
    "from nems.layers import FIR\n",
    "\n",
    "fir = FIR(shape=(1, 15), name='fir')\n",
    "fir_tf = fir.as_tensorflow_layer()()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = 4\n",
    "n_out = 4\n",
    "\n",
    "x = np.random.rand(10, 1000, 18)  # 10 stimuli (as spectrogram) 1000 bins each\n",
    "y = np.random.rand(10, 1000, n_out)   # 10 corresponding responses\n",
    "data = {'input': x}#, 'target': y}  # only include inputs (stim, state, etc)\n",
    "\n",
    "# TODO: this doesn't work right now b/c fir assumes it should be 4x15.\n",
    "#       Old NEMS got around that by multiplying first and last dims, but\n",
    "#       I was trying to avoid that...\n",
    "nems_model = Model.from_keywords(f'wc.18x1x{n_units}-fir.1x15x{n_units}')\n",
    "fir_tf = nems_model['fir'].as_tensorflow_layer()()\n",
    "# Check that input shape gets evaluated correctly\n",
    "fir_tf.call(keras.Input(shape=(1000, 1, 4), name='test', dtype='float32'))\n",
    "# TODO: not sure what the Lambda layer warning is about, but it's not happening\n",
    "#       during the actual model evaluation so maybe nothing to worry about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_layers = [layer.as_tensorflow_layer()() for layer in nems_model.layers]\n",
    "tf_model = build_model(\n",
    "    nems_model, tf_layers, data, eval_kwargs={'input_name': 'input'},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move NEMS Model.__repr__ to Model.summary() instead of Model.__str__?\n",
    "#       (or maybe both, but still switch __repr__ to compact version)\n",
    "tf_model.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss={\n",
    "        'fir': keras.losses.MeanSquaredError()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.fit(\n",
    "    data, {'fir': y}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.predict(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.layers[2].weights_to_values().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in tf_model.layers:\n",
    "    print(layer.weights_to_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF model built...\n",
      "Model: \"UnnamedModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000, 18)]        0         \n",
      "                                                                 \n",
      " wc (WeightChannelsTF)       (None, 1000, 2)           36        \n",
      "                                                                 \n",
      " fir (FiniteImpulseResponseT  (None, 1000, 1)          30        \n",
      " F)                                                              \n",
      "                                                                 \n",
      " wc0 (WeightChannelsTF)      (None, 1000, 1)           1         \n",
      "                                                                 \n",
      " relu (RectifiedLinearTF)    (None, 1000, 1)           3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70\n",
      "Trainable params: 67\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.3391\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3391\n",
      "TF model fit finished, parameters have been updated.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nems import Model\n",
    "\n",
    "input = np.random.rand(1, 1000, 18)  # 1 stimulus (as spectrogram) 1000 bins each\n",
    "target = np.random.rand(1, 1000, 1)   # 1 corresponding \"response\"\n",
    "model = Model.from_keywords('wc.18x2-fir.15x2-wc.1x1-relu.1')\n",
    "# model.freeze_layers('fir')\n",
    "# model.fit(input, target, backend='tf')  # TODO: arrays\n",
    "options = {'learning_rate': 1e2, 'epochs': 2}\n",
    "# with tf.device(\"/CPU:0\"):\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    tf_backend = model.fit(\n",
    "        input, target, backend='tf', fitter_options=options,\n",
    "        batch_size=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nems_prediction = tf_backend.nems_model.predict(input, batch_size=None)['output']\n",
    "nems_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1000, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_prediction = tf_backend.model.predict(input)\n",
    "tf_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(nems_prediction, tf_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mkltest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e04c614ea49137b728f9a88f47ebc62abd1dc770924cb0e56431acc2e9f8803"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
